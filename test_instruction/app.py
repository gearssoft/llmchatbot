import os

from langchain_openai.chat_models import ChatOpenAI

from langchain.prompts import ChatPromptTemplate
from langchain.schema.runnable import RunnablePassthrough,RunnableLambda

import streamlit as st

# .env íŒŒì¼ ë¡œë“œ ë° í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
from dotenv import load_dotenv
load_dotenv()

def log_chain(x):
    print("log : ", x) # ì´ì „ ë‹¨ê³„ì—ì„œ ë„˜ì–´ì˜¨ ë°ì´í„°ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
    st.write(x)
    return x

rbLogChain = RunnableLambda(log_chain)

def format_docs(docs):
    return "\n\n".join(document.page_content for document in docs)

st.set_page_config(
    page_title="instruction Chat",
    page_icon="ğŸ“ƒ",
)

# _inst.txt íŒŒì¼ ë¡œë“œ
with open('instruction.txt', 'r') as f:
    _instruction = f.read()

    with st.sidebar:
        instruction = st.text_area("Instructions",
        _instruction, height=200)
        
        if st.button("Save"):
            with open('temp_inst.txt', 'w') as f:
                f.write(instruction)
            st.write("Saved")

llm = ChatOpenAI(
    model_name=os.getenv('OPENAI_MODEL_NAME'), 
    # max_new_tokens=32, 
    temperature=0.1,
    timeout=10
    )

def create_chain(instruction):

    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                f"""
ë‹¤ìŒ "ëª…ë ¹"ì— ë”°ë¼ ë‹µë³€í•˜ì„¸ìš”.
"ëª…ë ¹" : {instruction}\n\n
=====================================
""",
            ),
            ("human", "ì§ˆë¬¸ : {question}"),
        ]
    )
    

    chain = (
        {
            
            "question": RunnablePassthrough(),
        }
        | prompt | rbLogChain
        | llm
    )
    
    return chain

question = st.chat_input("ask anything...")

if question :
    st.write(f"instruction : {instruction}")
    st.write(f"you : {question}")
    
    chain = create_chain(instruction)
    
    _answer = chain.invoke(question)
    st.write(_answer.content)
    
